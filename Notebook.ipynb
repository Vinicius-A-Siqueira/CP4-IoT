{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/lm+b2Hc7c6yyRdnuYhmR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vinicius-A-Siqueira/CP4-IoT/blob/main/Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVKc24cToHSm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "# Configurações gerais\n",
        "plt.rcParams.update({\n",
        "    \"figure.figsize\": (10, 4),\n",
        "    \"axes.grid\": True\n",
        "})\n",
        "\n",
        "DATA_FILE = \"household_power_consumption.txt\"\n",
        "\n",
        "if not Path(DATA_FILE).exists():\n",
        "    print(f\"⚠️ Arquivo '{DATA_FILE}' não encontrado na pasta atual: {Path.cwd()}\")\n",
        "    print(\"Coloque o arquivo na mesma pasta do notebook e rode novamente.\")\n",
        "else:\n",
        "    print(\"✅ Arquivo encontrado.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(filepath=DATA_FILE):\n",
        "    df = pd.read_csv(\n",
        "        filepath,\n",
        "        sep=';',\n",
        "        na_values=['?', 'NA', ''],\n",
        "        low_memory=False\n",
        "    )\n",
        "    # Conversão de tipos numéricos\n",
        "    numeric_cols = [\n",
        "        'Global_active_power','Global_reactive_power','Voltage',\n",
        "        'Global_intensity','Sub_metering_1','Sub_metering_2','Sub_metering_3'\n",
        "    ]\n",
        "    for c in numeric_cols:\n",
        "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
        "    return df\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    df = load_data()\n",
        "    print(\"Shape:\", df.shape)\n",
        "    print(\"Colunas:\", list(df.columns))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "F9BtnC0_wLT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1- Carregue o dataset e exiba as 10 primeiras linhas.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    display(df.head(10))\n",
        "else:\n",
        "    print(\"Carregue o arquivo na pasta do notebook e rode novamente.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1Qrya-gQwrV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2- Diferença entre Global_active_power e Global_reactive_power\n",
        "\n",
        "explanation = '''\n",
        "- **Global_active_power**: potência **ativa** consumida (kW) — energia que realiza trabalho útil (conversão em calor, movimento, etc.).\n",
        "- **Global_reactive_power**: potência **reativa** (kVAR) — energia alternada que não realiza trabalho útil diretamente; está associada a campos magnéticos/ elétricos em cargas indutivas/capacitivas e afeta a eficiência do sistema.\n",
        "'''\n",
        "print(explanation)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8Lj7zBZtw67T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3- Verifique valores ausentes e quantifique-os.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    missing_total = df.isna().sum()\n",
        "    print(\"Valores ausentes por coluna:\")\n",
        "    print(missing_total)\n",
        "    print(\"\\nTotal de valores ausentes:\", int(missing_total.sum()))\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "E2fX_zptxGDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4- Converter `Date` para datetime e criar coluna com o dia da semana.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    # Converter Date\n",
        "    df['Date_dt'] = pd.to_datetime(df['Date'], format='%d/%m/%Y', errors='coerce')\n",
        "    # Dia da semana (segunda=0, domingo=6)\n",
        "    df['weekday'] = df['Date_dt'].dt.day_name()  # nomes em inglês\n",
        "    display(df[['Date','Date_dt','weekday']].head())\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Hs0ZDdprxcU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5- Filtrar registros de 2007 e calcular média de consumo diário de Global_active_power.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    df_2007 = df[df['Date_dt'].dt.year == 2007].copy()\n",
        "    daily_mean_2007 = df_2007.groupby('Date_dt')['Global_active_power'].mean()\n",
        "    print(\"Média de consumo diário (kW) em 2007:\")\n",
        "    display(daily_mean_2007.describe())\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kvRu5i6Dx_r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6- Gráfico de linha da variação de Global_active_power em um dia escolhido.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    # Combinar Date e Time em datetime\n",
        "    df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%d/%m/%Y %H:%M:%S', errors='coerce')\n",
        "    # Escolha um dia com dados (ex: 2007-02-01)\n",
        "    day_choice = pd.Timestamp('2007-02-01')\n",
        "    mask = (df['DateTime'].dt.date == day_choice.date())\n",
        "    day_df = df.loc[mask].sort_values('DateTime')\n",
        "    plt.figure()\n",
        "    plt.plot(day_df['DateTime'], day_df['Global_active_power'])\n",
        "    plt.title(f\"Global_active_power ao longo do dia — {day_choice.date()}\")\n",
        "    plt.xlabel(\"Hora\")\n",
        "    plt.ylabel(\"kW\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NM5jiY17yaEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7- Histograma de Voltage e observações sobre a distribuição.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    plt.figure()\n",
        "    df['Voltage'].dropna().hist(bins=50)\n",
        "    plt.title(\"Histograma — Voltage\")\n",
        "    plt.xlabel(\"Voltage (V)\")\n",
        "    plt.ylabel(\"Frequência\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Observação: Em geral, espera-se uma distribuição aproximadamente unimodal, concentrada próximo à tensão nominal (em torno de ~240 V), com alguma dispersão.\")\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5TKhufQKylFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8- Consumo médio por mês em todo o período.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    df['YearMonth'] = df['Date_dt'].dt.to_period('M')\n",
        "    monthly_mean = df.groupby('YearMonth')['Global_active_power'].mean().to_timestamp()\n",
        "    display(monthly_mean.head())\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IaMHP7ICyttv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9- Dia com maior consumo de energia ativa global (média diária).\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    daily_mean = df.groupby('Date_dt')['Global_active_power'].mean()\n",
        "    max_day = daily_mean.idxmax()\n",
        "    print(\"Dia com maior consumo médio de Global_active_power:\", max_day.date(), \"—\", daily_mean.max(), \"kW\")\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qlAP0Pm5zBPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10- Consumo médio: dias de semana vs finais de semana.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    df['is_weekend'] = df['Date_dt'].dt.weekday >= 5\n",
        "    daily = df.groupby(['Date_dt','is_weekend'])['Global_active_power'].mean().reset_index()\n",
        "    weekday_mean = daily.loc[~daily['is_weekend'],'Global_active_power'].mean()\n",
        "    weekend_mean = daily.loc[daily['is_weekend'],'Global_active_power'].mean()\n",
        "    print(f\"Média (dias de semana): {weekday_mean:.4f} kW\")\n",
        "    print(f\"Média (finais de semana): {weekend_mean:.4f} kW\")\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7mMKT723zIZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11- Correlação entre GA, GR, Voltage e GI.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    corr_cols = ['Global_active_power','Global_reactive_power','Voltage','Global_intensity']\n",
        "    corr = df[corr_cols].corr()\n",
        "    display(corr)\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7vYvta-hzRpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12- Nova variável Total_Sub_metering.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    df['Total_Sub_metering'] = df[['Sub_metering_1','Sub_metering_2','Sub_metering_3']].sum(axis=1, skipna=True)\n",
        "    display(df[['Sub_metering_1','Sub_metering_2','Sub_metering_3','Total_Sub_metering']].head())\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sfrUS599zbnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13- Verificar mês em que Total_Sub_metering ultrapassa a média de Global_active_power.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    monthly = df.groupby('YearMonth').agg({\n",
        "        'Total_Sub_metering':'mean',\n",
        "        'Global_active_power':'mean'\n",
        "    })\n",
        "    cond = monthly['Total_Sub_metering'] > monthly['Global_active_power']\n",
        "    result = monthly[cond]\n",
        "    print(\"Meses onde a média de Total_Sub_metering > média de Global_active_power:\")\n",
        "    display(result)\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "brhDyCDhzi5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 14- Série temporal de Voltage para 2008.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    mask_2008 = df['Date_dt'].dt.year == 2008\n",
        "    df_2008 = df.loc[mask_2008].copy()\n",
        "    df_2008 = df_2008.sort_values('DateTime')\n",
        "    plt.figure()\n",
        "    plt.plot(df_2008['DateTime'], df_2008['Voltage'])\n",
        "    plt.title(\"Voltage — Série Temporal (2008)\")\n",
        "    plt.xlabel(\"Data\")\n",
        "    plt.ylabel(\"Voltage (V)\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FzyDo-W4ztRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 15- Comparar consumo entre meses de verão e inverno (Hemisfério Norte).\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    # Verão (HN): Jun, Jul, Ago; Inverno (HN): Dez, Jan, Fev\n",
        "    df['month'] = df['Date_dt'].dt.month\n",
        "    summer_months = [6,7,8]\n",
        "    winter_months = [12,1,2]\n",
        "    summer = df[df['month'].isin(summer_months)].groupby('Date_dt')['Global_active_power'].mean().mean()\n",
        "    winter = df[df['month'].isin(winter_months)].groupby('Date_dt')['Global_active_power'].mean().mean()\n",
        "    print(f\"Média verão (HN): {summer:.4f} kW\")\n",
        "    print(f\"Média inverno (HN): {winter:.4f} kW\")\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "id": "BrXJmOtgz0Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 16- Amostragem aleatória de 1% e comparação da distribuição de Global_active_power.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    full = df['Global_active_power'].dropna()\n",
        "    sample = full.sample(frac=0.01, random_state=42)\n",
        "    plt.figure()\n",
        "    full.hist(bins=60, alpha=0.6)\n",
        "    plt.title(\"Distribuição — Base Completa (Global_active_power)\")\n",
        "    plt.xlabel(\"kW\")\n",
        "    plt.ylabel(\"Frequência\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    sample.hist(bins=60, alpha=0.6)\n",
        "    plt.title(\"Distribuição — Amostra 1% (Global_active_power)\")\n",
        "    plt.xlabel(\"kW\")\n",
        "    plt.ylabel(\"Frequência\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Compare visualmente as distribuições para similaridade geral de formato/caudas.\")\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LfY9KpbTz_Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 17- Normalização (Min-Max Scaling) das variáveis numéricas principais.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    num_cols = ['Global_active_power','Global_reactive_power','Voltage','Global_intensity',\n",
        "                'Sub_metering_1','Sub_metering_2','Sub_metering_3','Total_Sub_metering']\n",
        "    data_num = df[num_cols].dropna()\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled = scaler.fit_transform(data_num)\n",
        "    scaled_df = pd.DataFrame(scaled, columns=num_cols, index=data_num.index)\n",
        "    display(scaled_df.head())\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "id": "nUFlIGRp0H8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 18- K-means para segmentar dias (3 clusters) e interpretação.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    # Featurização diária\n",
        "    feats = df.groupby('Date_dt').agg({\n",
        "        'Global_active_power':'mean',\n",
        "        'Global_reactive_power':'mean',\n",
        "        'Voltage':'mean',\n",
        "        'Global_intensity':'mean',\n",
        "        'Total_Sub_metering':'mean'\n",
        "    }).dropna()\n",
        "\n",
        "    scaler_days = MinMaxScaler()\n",
        "    X = scaler_days.fit_transform(feats)\n",
        "\n",
        "    km = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "    feats['cluster'] = km.fit_predict(X)\n",
        "\n",
        "    print(\"Tamanho dos clusters:\")\n",
        "    print(feats['cluster'].value_counts().sort_index())\n",
        "\n",
        "    print(\"\\nMédias por cluster:\")\n",
        "    display(feats.groupby('cluster').mean())\n",
        "\n",
        "    # Interpretação (texto)\n",
        "    print(\"\\nInterpretação geral: clusters com maior média de Global_active_power/Total_Sub_metering tendem a representar dias de maior consumo; tensões/reativa podem distinguir perfis elétricos distintos.\")\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")\n"
      ],
      "metadata": {
        "id": "2cjiNWMY0OIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 19- Decomposição de série temporal (6 meses) para Global_active_power.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    # Série por hora para 6 meses iniciando em 2007-01 (ajuste se desejar)\n",
        "    df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%d/%m/%Y %H:%M:%S', errors='coerce')\n",
        "    ts_hourly = df.set_index('DateTime')['Global_active_power'].resample('1H').mean().dropna()\n",
        "\n",
        "    # Seleciona janela de 6 meses\n",
        "    start = pd.Timestamp('2007-01-01')\n",
        "    end = start + pd.DateOffset(months=6)\n",
        "    ts_6m = ts_hourly.loc[start:end].dropna()\n",
        "\n",
        "    result = seasonal_decompose(ts_6m, model='additive', period=24)  # sazonalidade diária (24h)\n",
        "    # Plot manual em figuras separadas para cumprir a regra (1 por figura)\n",
        "    plt.figure()\n",
        "    plt.plot(result.observed.index, result.observed.values)\n",
        "    plt.title(\"Decomposição — Observado (6 meses)\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(result.trend.index, result.trend.values)\n",
        "    plt.title(\"Decomposição — Tendência\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(result.seasonal.index, result.seasonal.values)\n",
        "    plt.title(\"Decomposição — Sazonalidade (≈24h)\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(result.resid.index, result.resid.values)\n",
        "    plt.title(\"Decomposição — Resíduo\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "id": "VEhKaH-m1CaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 20- Regressão linear simples para prever Global_active_power a partir de Global_intensity.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    data = df[['Global_active_power','Global_intensity']].dropna()\n",
        "    X = data[['Global_intensity']].values\n",
        "    y = data['Global_active_power'].values\n",
        "    # Treino/teste simples (holdout)\n",
        "    n = len(data)\n",
        "    split = int(n*0.8)\n",
        "    X_train, X_test = X[:split], X[split:]\n",
        "    y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "    lr = LinearRegression()\n",
        "    lr.fit(X_train, y_train)\n",
        "    y_pred = lr.predict(X_test)\n",
        "    # Calculate RMSE by taking the square root of the mean squared error\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "    print(\"Coeficiente (slope):\", lr.coef_[0])\n",
        "    print(\"Intercepto:\", lr.intercept_)\n",
        "    print(\"RMSE (teste):\", rmse)\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WIoRTtbH1oyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 21- Séries temporais por hora — índice datetime, reamostragem 1h e horários de maior consumo.\n",
        "\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%d/%m/%Y %H:%M:%S', errors='coerce')\n",
        "    ts = df.set_index('DateTime')['Global_active_power'].resample('1H').mean()\n",
        "    display(ts.head())\n",
        "\n",
        "    # Horários de maior consumo médio ao longo do dia (0–23)\n",
        "    hourly_mean = df.set_index('DateTime')['Global_active_power'].groupby(df['DateTime'].dt.hour).mean()\n",
        "    print(\"Médias por hora (0–23):\")\n",
        "    display(hourly_mean.sort_values(ascending=False))\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Vf_x1dV82DPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 22- Autocorrelação do consumo (lags 1h, 24h, 48h).\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    ts = df.set_index('DateTime')['Global_active_power'].resample('1H').mean().dropna()\n",
        "    acf_1 = ts.autocorr(lag=1)\n",
        "    acf_24 = ts.autocorr(lag=24)\n",
        "    acf_48 = ts.autocorr(lag=48)\n",
        "    print(f\"Autocorrelação 1h:  {acf_1:.4f}\")\n",
        "    print(f\"Autocorrelação 24h: {acf_24:.4f}\")\n",
        "    print(f\"Autocorrelação 48h: {acf_48:.4f}\")\n",
        "    print(\"Padrões diários existem quando a autocorrelação em 24h é significativamente positiva.\")\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RzGmLSLa2U-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 23- PCA (2 componentes) nas variáveis GA, GR, Voltage e GI.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    cols = ['Global_active_power','Global_reactive_power','Voltage','Global_intensity']\n",
        "    data_pca = df[cols].dropna()\n",
        "    scaler_pca = MinMaxScaler()\n",
        "    Xp = scaler_pca.fit_transform(data_pca)\n",
        "\n",
        "    pca = PCA(n_components=2, random_state=42)\n",
        "    pca_scores = pca.fit_transform(Xp)\n",
        "    print(\"Variância explicada por componente:\", pca.explained_variance_ratio_)\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "id": "q81n7yaR2pO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 24- Visualização de clusters no espaço do PCA (3 clusters).\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    cols = ['Global_active_power','Global_reactive_power','Voltage','Global_intensity']\n",
        "    data_pca = df[cols].dropna()\n",
        "    scaler_pca = MinMaxScaler()\n",
        "    Xp = scaler_pca.fit_transform(data_pca)\n",
        "    pca = PCA(n_components=2, random_state=42)\n",
        "    Z = pca.fit_transform(Xp)\n",
        "\n",
        "    km2 = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "    labels = km2.fit_predict(Z)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.scatter(Z[:,0], Z[:,1], s=5, alpha=0.5, c=labels)\n",
        "    plt.title(\"PCA (2D) com K-Means (k=3)\")\n",
        "    plt.xlabel(\"PC1\")\n",
        "    plt.ylabel(\"PC2\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Pergunta: os grupos se separam de forma clara? Observe a sobreposição dos pontos no plano.\")\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "k1FVY3W02ule"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 25 Regressão Linear vs Polinomial (grau 2) — Global_active_power ~ Voltage.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    data = df[['Global_active_power','Voltage']].dropna()\n",
        "    X = data[['Voltage']].values\n",
        "    y = data['Global_active_power'].values\n",
        "\n",
        "    n = len(data)\n",
        "    split = int(n*0.8)\n",
        "    X_train, X_test = X[:split], X[split:]\n",
        "    y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "    # Linear\n",
        "    lr2 = LinearRegression()\n",
        "    lr2.fit(X_train, y_train)\n",
        "    y_pred_lin = lr2.predict(X_test)\n",
        "    rmse_lin = np.sqrt(mean_squared_error(y_test, y_pred_lin))\n",
        "\n",
        "    # Polinomial grau 2\n",
        "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "    X_train_poly = poly.fit_transform(X_train)\n",
        "    X_test_poly = poly.transform(X_test)\n",
        "\n",
        "    lr_poly = LinearRegression()\n",
        "    lr_poly.fit(X_train_poly, y_train)\n",
        "    y_pred_poly = lr_poly.predict(X_test_poly)\n",
        "    rmse_poly = np.sqrt(mean_squared_error(y_test, y_pred_poly))\n",
        "\n",
        "    print(f\"RMSE Linear:     {rmse_lin:.5f}\")\n",
        "    print(f\"RMSE Polinomial: {rmse_poly:.5f}\")\n",
        "\n",
        "    # Curvas ajustadas (amostra de teste ordenada por Voltage para visual)\n",
        "    order = np.argsort(X_test[:,0])\n",
        "    Xo = X_test[order]\n",
        "    yo_lin = y_pred_lin[order]\n",
        "    yo_poly = y_pred_poly[order]\n",
        "\n",
        "    plt.figure()\n",
        "    plt.scatter(X_test[:,0], y_test, s=5, alpha=0.3)\n",
        "    plt.plot(Xo[:,0], yo_lin)\n",
        "    plt.title(\"Ajuste — Regressão Linear (teste)\")\n",
        "    plt.xlabel(\"Voltage (V)\")\n",
        "    plt.ylabel(\"Global_active_power (kW)\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.scatter(X_test[:,0], y_test, s=5, alpha=0.3)\n",
        "    plt.plot(Xo[:,0], yo_poly)\n",
        "    plt.title(\"Ajuste — Regressão Polinomial Grau 2 (teste)\")\n",
        "    plt.xlabel(\"Voltage (V)\")\n",
        "    plt.ylabel(\"Global_active_power (kW)\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PBwsCChe28jY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "plt.rcParams.update({'figure.figsize': (10,4), 'axes.grid': True})\n",
        "\n",
        "DATA_FILE = \"energydata_complete.csv\"\n",
        "if not Path(DATA_FILE).exists():\n",
        "    print(f\"⚠️ Arquivo '{DATA_FILE}' não encontrado em {Path.cwd()}\")\n",
        "else:\n",
        "    print(\"✅ Arquivo encontrado.\")"
      ],
      "metadata": {
        "id": "HNp3oJ9W4Opl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 26- Carregamento e inspeção inicial\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    df = pd.read_csv(DATA_FILE)\n",
        "    print('Shape:', df.shape)\n",
        "    print('\\n.info():')\n",
        "    display(df.info())\n",
        "    print('\\n.describe():')\n",
        "    display(df.describe().T)\n",
        "else:\n",
        "    print(\"Coloque o arquivo na mesma pasta do notebook e rode novamente.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "U1WnF9CJ4gF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 27- Distribuição do consumo — Appliances\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    # Histograma\n",
        "    plt.figure()\n",
        "    df['Appliances'].hist(bins=50)\n",
        "    plt.title(\"Histograma — Appliances\")\n",
        "    plt.xlabel(\"Appliances (Wh)\")\n",
        "    plt.ylabel(\"Frequência\")\n",
        "    plt.show()\n",
        "\n",
        "    # Série temporal (amostra para visualização se for muito grande)\n",
        "    plt.figure()\n",
        "    # converter date se existir coluna 'date' e plotar uma janela de 7 dias\n",
        "    if 'date' in df.columns:\n",
        "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "        sample = df.set_index('date')['Appliances'].resample('1H').mean().dropna()\n",
        "        sample_window = sample.sort_index().iloc[:24*7]  # primeira semana\n",
        "        plt.plot(sample_window.index, sample_window.values)\n",
        "        plt.title(\"Série temporal — Appliances (primeira semana)\")\n",
        "        plt.xlabel(\"Data\")\n",
        "        plt.ylabel(\"Appliances (Wh)\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.plot(df['Appliances'].values[:24*7])\n",
        "        plt.title(\"Série temporal (primeiros 7 dias aproximados) — Appliances\")\n",
        "        plt.xlabel(\"Índice\")\n",
        "        plt.ylabel(\"Appliances (Wh)\")\n",
        "        plt.show()\n",
        "\n",
        "    print(\"Pergunta: o consumo tende a se concentrar em valores baixos ou altos?\")\n",
        "    print(\"Observe o histograma e a escala (Wh). Em muitos datasets de consumo doméstico, a massa está em valores baixos com cauda à direita.\")\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "id": "u4VXPf1C4s_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 28- Correlações com variáveis ambientais.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    # Selecionar variáveis ambientais típicas (ajuste se nomes diferentes)\n",
        "    candidates = ['T_out','T1','T2','T3','T4','T5','T6','T7','T8','T9',\n",
        "                  'RH_out','RH_1','RH_2','RH_3','RH_4','RH_5','RH_6','RH_7','RH_8','RH_9']\n",
        "    present = [c for c in candidates if c in df.columns]\n",
        "    cols = ['Appliances'] + present\n",
        "    corr = df[cols].corr()\n",
        "    display(corr.loc['Appliances'].sort_values(ascending=False))\n",
        "    print(\"\\nPergunta: quais fatores têm mais relação com o consumo?\")\n",
        "    print(\"Olhe os maiores valores absolutos de correlação com 'Appliances'.\")\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "id": "N0wCaozeH0bS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 29- Normalização (Min-Max Scaling) das variáveis numéricas.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    scaler = MinMaxScaler()\n",
        "    df_scaled = df.copy()\n",
        "    df_scaled[num_cols] = scaler.fit_transform(df[num_cols].fillna(0))\n",
        "    print(\"Exemplo das colunas numéricas escaladas:\")\n",
        "    display(df_scaled[num_cols].head())\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "id": "hs-amyCaIA2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 30- PCA — reduzir para 2 componentes principais.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    numeric = df.select_dtypes(include=[np.number]).dropna(axis=1, how='all')\n",
        "    cols_pca = numeric.columns.tolist()\n",
        "    Xp = MinMaxScaler().fit_transform(numeric.fillna(0))\n",
        "    pca = PCA(n_components=2, random_state=42)\n",
        "    Z = pca.fit_transform(Xp)\n",
        "    print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
        "    plt.figure()\n",
        "    plt.scatter(Z[:,0], Z[:,1], s=4, alpha=0.6)\n",
        "    plt.title(\"PCA — 2 componentes (todos os registros)\")\n",
        "    plt.xlabel(\"PC1\")\n",
        "    plt.ylabel(\"PC2\")\n",
        "    plt.show()\n",
        "    print(\"Pergunta: aparecem padrões ou agrupamentos naturais? Observe o gráfico para possíveis regiões de maior densidade.\")\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "id": "az4sCci8IGlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 31- Regressão Linear Múltipla — Appliances ~ variáveis ambientais.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    # Definir features ambientais — escolher as presentes\n",
        "    env_candidates = ['T_out','RH_out']  # defaults\n",
        "    # expandir se colunas T1.. existirem: escolha algumas representativas\n",
        "    for c in ['T1','T2','T3','RH_1','RH_2','RH_3']:\n",
        "        if c in df.columns:\n",
        "            env_candidates.append(c)\n",
        "    features = [c for c in env_candidates if c in df.columns]\n",
        "    data = df[features + ['Appliances']].dropna()\n",
        "    X = data[features].values\n",
        "    y = data['Appliances'].values\n",
        "\n",
        "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "\n",
        "    lr = LinearRegression()\n",
        "    lr.fit(X_train,y_train)\n",
        "    y_pred = lr.predict(X_test)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(\"Features usadas:\", features)\n",
        "    print(\"R^2:\", r2)\n",
        "    print(\"RMSE:\", rmse)\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "id": "eqr_Bq2vINdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 32- Random Forest Regressor — comparar com Regressão Linear.\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    # Reusar X_train, X_test, y_train, y_test do passo anterior (se não existirem, refazer)\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test\n",
        "    except NameError:\n",
        "        data = df[features + ['Appliances']].dropna()\n",
        "        features = [c for c in env_candidates if c in df.columns] # Re-define features if necessary\n",
        "        X = data[features].values\n",
        "        y = data['Appliances'].values\n",
        "        X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "\n",
        "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    rf.fit(X_train,y_train)\n",
        "    y_pred_rf = rf.predict(X_test)\n",
        "    rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "    print(\"RMSE Regressão Linear (ref):\", rmse)\n",
        "    print(\"RMSE Random Forest:\", rmse_rf)\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "id": "MfPWjXEbIWUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 33- K-Means clustering (k=3..5)\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    # Usar apenas variáveis numéricas escaladas para clustering\n",
        "    num = df.select_dtypes(include=[np.number]).fillna(0)\n",
        "    num_s = MinMaxScaler().fit_transform(num)\n",
        "    inertias = {}\n",
        "    for k in range(3,6):\n",
        "        km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "        km.fit(num_s)\n",
        "        inertias[k] = km.inertia_\n",
        "        print(f\"k={k}, inertia={km.inertia_:.2f}\")\n",
        "    # Aplicar k=3 por exemplo e mostrar centros (desescalados apenas para interpretação relativa)\n",
        "    km3 = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "    labels = km3.fit_predict(num_s)\n",
        "    df['k3_cluster'] = labels\n",
        "    print(\"Tamanho dos clusters (k=3):\", df['k3_cluster'].value_counts().to_dict())\n",
        "    display(df.groupby('k3_cluster')['Appliances'].describe())\n",
        "    print(\"Interprete os perfis por média/mediana de 'Appliances' e outras variáveis.\")\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "id": "EQCoZMT_Ih4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 34- Classificação binária — alto vs baixo consumo\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    median = df['Appliances'].median()\n",
        "    df['high_consumption'] = (df['Appliances'] > median).astype(int)\n",
        "    print(\"Mediana Appliances:\", median)\n",
        "    display(df['high_consumption'].value_counts())\n",
        "\n",
        "    # Selecionar features — usar as mesmas ambientais do modelo de regressão\n",
        "    data_cls = df[features + ['high_consumption']].dropna()\n",
        "    Xc = data_cls[features].values\n",
        "    yc = data_cls['high_consumption'].values\n",
        "    Xc_train,Xc_test,yc_train,yc_test = train_test_split(Xc,yc,test_size=0.2,random_state=42)\n",
        "    # Logistic Regression\n",
        "    log = LogisticRegression(max_iter=1000)\n",
        "    log.fit(Xc_train,yc_train)\n",
        "    y_pred_log = log.predict(Xc_test)\n",
        "    # Random Forest Classifier\n",
        "    rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rfc.fit(Xc_train,yc_train)\n",
        "    y_pred_rfc = rfc.predict(Xc_test)\n",
        "\n",
        "    print(\"Modelos treinados: Logistic Regression e Random Forest (Classifier)\")\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")"
      ],
      "metadata": {
        "id": "S898yYzGIwkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 35- Avaliação de classificação\n",
        "\n",
        "if Path(DATA_FILE).exists():\n",
        "    print(\"=== Logistic Regression ===\")\n",
        "    print(\"Accuracy:\", accuracy_score(yc_test, y_pred_log))\n",
        "    print(\"Precision:\", precision_score(yc_test, y_pred_log))\n",
        "    print(\"Recall:\", recall_score(yc_test, y_pred_log))\n",
        "    print(\"F1:\", f1_score(yc_test, y_pred_log))\n",
        "    print(\"\\nConfusion matrix:\")\n",
        "    print(confusion_matrix(yc_test, y_pred_log))\n",
        "\n",
        "    print(\"\\n=== Random Forest Classifier ===\")\n",
        "    print(\"Accuracy:\", accuracy_score(yc_test, y_pred_rfc))\n",
        "    print(\"Precision:\", precision_score(yc_test, y_pred_rfc))\n",
        "    print(\"Recall:\", recall_score(yc_test, y_pred_rfc))\n",
        "    print(\"F1:\", f1_score(yc_test, y_pred_rfc))\n",
        "    print(\"\\nConfusion matrix:\")\n",
        "    print(confusion_matrix(yc_test, y_pred_rfc))\n",
        "\n",
        "    print(\"\\nPergunta: o modelo erra mais para alto ou para baixo consumo?\")\n",
        "    print(\"Compare valores de falso positivo (prevê alto quando é baixo) e falso negativo (prevê baixo quando é alto) nas matrizes de confusão.\")\n",
        "else:\n",
        "    print(\"Arquivo não encontrado.\")\n"
      ],
      "metadata": {
        "id": "xNwWq1gDI2QG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}