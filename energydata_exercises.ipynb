{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "436d47a7",
   "metadata": {},
   "source": [
    "\n",
    "# Exercícios — energydata_complete.csv (26–35)\n",
    "\n",
    "> Coloque o arquivo **`energydata_complete.csv`** na **mesma pasta** deste notebook antes de rodar.\n",
    ">\n",
    "> Este notebook cobre:\n",
    "> - Carregamento e inspeção inicial\n",
    "> - Visualizações (histogramas, séries temporais)\n",
    "> - Correlações e PCA\n",
    "> - Modelos: Regressão Linear Múltipla, Random Forest Regressor\n",
    "> - Clustering K-Means\n",
    "> - Classificação binária (alto/baixo consumo) com métricas\n",
    ">\n",
    "> Bibliotecas usadas: **pandas, numpy, matplotlib, scikit-learn, seaborn (opcional)**, **statsmodels** (opcional).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2a7fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %pip install pandas numpy matplotlib scikit-learn seaborn statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb1a2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "plt.rcParams.update({'figure.figsize': (10,4), 'axes.grid': True})\n",
    "\n",
    "DATA_FILE = \"energydata_complete.csv\"\n",
    "if not Path(DATA_FILE).exists():\n",
    "    print(f\"⚠️ Arquivo '{DATA_FILE}' não encontrado em {Path.cwd()}\")\n",
    "else:\n",
    "    print(\"✅ Arquivo encontrado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10071bca",
   "metadata": {},
   "source": [
    "## 26) Carregamento e inspeção inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9241f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if Path(DATA_FILE).exists():\n",
    "    df = pd.read_csv(DATA_FILE)\n",
    "    print('Shape:', df.shape)\n",
    "    print('\\n.info():')\n",
    "    display(df.info())\n",
    "    print('\\n.describe():')\n",
    "    display(df.describe().T)\n",
    "else:\n",
    "    print(\"Coloque o arquivo na mesma pasta do notebook e rode novamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f5be77",
   "metadata": {},
   "source": [
    "## 27) Distribuição do consumo — `Appliances`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d56dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if Path(DATA_FILE).exists():\n",
    "    # Histograma\n",
    "    plt.figure()\n",
    "    df['Appliances'].hist(bins=50)\n",
    "    plt.title(\"Histograma — Appliances\")\n",
    "    plt.xlabel(\"Appliances (Wh)\")\n",
    "    plt.ylabel(\"Frequência\")\n",
    "    plt.show()\n",
    "\n",
    "    # Série temporal (amostra para visualização se for muito grande)\n",
    "    plt.figure()\n",
    "    # converter date se existir coluna 'date' e plotar uma janela de 7 dias\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "        sample = df.set_index('date')['Appliances'].resample('1H').mean().dropna()\n",
    "        sample_window = sample.sort_index().iloc[:24*7]  # primeira semana\n",
    "        plt.plot(sample_window.index, sample_window.values)\n",
    "        plt.title(\"Série temporal — Appliances (primeira semana)\")\n",
    "        plt.xlabel(\"Data\")\n",
    "        plt.ylabel(\"Appliances (Wh)\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.plot(df['Appliances'].values[:24*7])\n",
    "        plt.title(\"Série temporal (primeiros 7 dias aproximados) — Appliances\")\n",
    "        plt.xlabel(\"Índice\")\n",
    "        plt.ylabel(\"Appliances (Wh)\")\n",
    "        plt.show()\n",
    "\n",
    "    print(\"Pergunta: o consumo tende a se concentrar em valores baixos ou altos?\")\n",
    "    print(\"Observe o histograma e a escala (Wh). Em muitos datasets de consumo doméstico, a massa está em valores baixos com cauda à direita.\")\n",
    "else:\n",
    "    print(\"Arquivo não encontrado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b36f6",
   "metadata": {},
   "source": [
    "## 28) Correlações com variáveis ambientais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c700753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if Path(DATA_FILE).exists():\n",
    "    # Selecionar variáveis ambientais típicas (ajuste se nomes diferentes)\n",
    "    candidates = ['T_out','T1','T2','T3','T4','T5','T6','T7','T8','T9',\n",
    "                  'RH_out','RH_1','RH_2','RH_3','RH_4','RH_5','RH_6','RH_7','RH_8','RH_9']\n",
    "    present = [c for c in candidates if c in df.columns]\n",
    "    cols = ['Appliances'] + present\n",
    "    corr = df[cols].corr()\n",
    "    display(corr.loc['Appliances'].sort_values(ascending=False))\n",
    "    print(\"\\nPergunta: quais fatores têm mais relação com o consumo?\")\n",
    "    print(\"Olhe os maiores valores absolutos de correlação com 'Appliances'.\")\n",
    "else:\n",
    "    print(\"Arquivo não encontrado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d39e03",
   "metadata": {},
   "source": [
    "## 29) Normalização (Min-Max Scaling) das variáveis numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de42cc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if Path(DATA_FILE).exists():\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    scaler = MinMaxScaler()\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled[num_cols] = scaler.fit_transform(df[num_cols].fillna(0))\n",
    "    print(\"Exemplo das colunas numéricas escaladas:\")\n",
    "    display(df_scaled[num_cols].head())\n",
    "else:\n",
    "    print(\"Arquivo não encontrado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c59a1",
   "metadata": {},
   "source": [
    "## 30) PCA — reduzir para 2 componentes principais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1120ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if Path(DATA_FILE).exists():\n",
    "    numeric = df.select_dtypes(include=[np.number]).dropna(axis=1, how='all')\n",
    "    cols_pca = numeric.columns.tolist()\n",
    "    Xp = MinMaxScaler().fit_transform(numeric.fillna(0))\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    Z = pca.fit_transform(Xp)\n",
    "    print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "    plt.figure()\n",
    "    plt.scatter(Z[:,0], Z[:,1], s=4, alpha=0.6)\n",
    "    plt.title(\"PCA — 2 componentes (todos os registros)\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.show()\n",
    "    print(\"Pergunta: aparecem padrões ou agrupamentos naturais? Observe o gráfico para possíveis regiões de maior densidade.\")\n",
    "else:\n",
    "    print(\"Arquivo não encontrado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ff5b16",
   "metadata": {},
   "source": [
    "## 31) Regressão Linear Múltipla — Appliances ~ variáveis ambientais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2904da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if Path(DATA_FILE).exists():\n",
    "    # Definir features ambientais — escolher as presentes\n",
    "    env_candidates = ['T_out','RH_out']  # defaults\n",
    "    # expandir se colunas T1.. existirem: escolha algumas representativas\n",
    "    for c in ['T1','T2','T3','RH_1','RH_2','RH_3']:\n",
    "        if c in df.columns:\n",
    "            env_candidates.append(c)\n",
    "    features = [c for c in env_candidates if c in df.columns]\n",
    "    data = df[features + ['Appliances']].dropna()\n",
    "    X = data[features].values\n",
    "    y = data['Appliances'].values\n",
    "\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train,y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Features usadas:\", features)\n",
    "    print(\"R^2:\", r2)\n",
    "    print(\"RMSE:\", rmse)\n",
    "else:\n",
    "    print(\"Arquivo não encontrado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543eba7d",
   "metadata": {},
   "source": [
    "## 32) Random Forest Regressor — comparar com Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c513f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if Path(DATA_FILE).exists():\n",
    "    # Reusar X_train, X_test, y_train, y_test do passo anterior (se não existirem, refazer)\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test\n",
    "    except NameError:\n",
    "        data = df[features + ['Appliances']].dropna()\n",
    "        X = data[features].values\n",
    "        y = data['Appliances'].values\n",
    "        X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train,y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    rmse_rf = mean_squared_error(y_test, y_pred_rf, squared=False)\n",
    "    print(\"RMSE Regressão Linear (ref):\", rmse)\n",
    "    print(\"RMSE Random Forest:\", rmse_rf)\n",
    "else:\n",
    "    print(\"Arquivo não encontrado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ef58b",
   "metadata": {},
   "source": [
    "## 33) K-Means clustering (k=3..5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc526b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if Path(DATA_FILE).exists():\n",
    "    # Usar apenas variáveis numéricas escaladas para clustering\n",
    "    num = df.select_dtypes(include=[np.number]).fillna(0)\n",
    "    num_s = MinMaxScaler().fit_transform(num)\n",
    "    inertias = {}\n",
    "    for k in range(3,6):\n",
    "        km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        km.fit(num_s)\n",
    "        inertias[k] = km.inertia_\n",
    "        print(f\"k={k}, inertia={km.inertia_:.2f}\")\n",
    "    # Aplicar k=3 por exemplo e mostrar centros (desescalados apenas para interpretação relativa)\n",
    "    km3 = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "    labels = km3.fit_predict(num_s)\n",
    "    df['k3_cluster'] = labels\n",
    "    print(\"Tamanho dos clusters (k=3):\", df['k3_cluster'].value_counts().to_dict())\n",
    "    display(df.groupby('k3_cluster')['Appliances'].describe())\n",
    "    print(\"Interprete os perfis por média/mediana de 'Appliances' e outras variáveis.\")\n",
    "else:\n",
    "    print(\"Arquivo não encontrado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa66312",
   "metadata": {},
   "source": [
    "## 34) Classificação binária — alto vs baixo consumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbb91bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if Path(DATA_FILE).exists():\n",
    "    median = df['Appliances'].median()\n",
    "    df['high_consumption'] = (df['Appliances'] > median).astype(int)\n",
    "    print(\"Mediana Appliances:\", median)\n",
    "    display(df['high_consumption'].value_counts())\n",
    "\n",
    "    # Selecionar features — usar as mesmas ambientais do modelo de regressão\n",
    "    data_cls = df[features + ['high_consumption']].dropna()\n",
    "    Xc = data_cls[features].values\n",
    "    yc = data_cls['high_consumption'].values\n",
    "    Xc_train,Xc_test,yc_train,yc_test = train_test_split(Xc,yc,test_size=0.2,random_state=42)\n",
    "    # Logistic Regression\n",
    "    log = LogisticRegression(max_iter=1000)\n",
    "    log.fit(Xc_train,yc_train)\n",
    "    y_pred_log = log.predict(Xc_test)\n",
    "    # Random Forest Classifier\n",
    "    rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rfc.fit(Xc_train,yc_train)\n",
    "    y_pred_rfc = rfc.predict(Xc_test)\n",
    "\n",
    "    print(\"Modelos treinados: Logistic Regression e Random Forest (Classifier)\")\n",
    "else:\n",
    "    print(\"Arquivo não encontrado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afbfa1d",
   "metadata": {},
   "source": [
    "## 35) Avaliação de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab597ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if Path(DATA_FILE).exists():\n",
    "    print(\"=== Logistic Regression ===\")\n",
    "    print(\"Accuracy:\", accuracy_score(yc_test, y_pred_log))\n",
    "    print(\"Precision:\", precision_score(yc_test, y_pred_log))\n",
    "    print(\"Recall:\", recall_score(yc_test, y_pred_log))\n",
    "    print(\"F1:\", f1_score(yc_test, y_pred_log))\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    print(confusion_matrix(yc_test, y_pred_log))\n",
    "\n",
    "    print(\"\\n=== Random Forest Classifier ===\")\n",
    "    print(\"Accuracy:\", accuracy_score(yc_test, y_pred_rfc))\n",
    "    print(\"Precision:\", precision_score(yc_test, y_pred_rfc))\n",
    "    print(\"Recall:\", recall_score(yc_test, y_pred_rfc))\n",
    "    print(\"F1:\", f1_score(yc_test, y_pred_rfc))\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    print(confusion_matrix(yc_test, y_pred_rfc))\n",
    "\n",
    "    print(\"\\nPergunta: o modelo erra mais para alto ou para baixo consumo?\")\n",
    "    print(\"Compare valores de falso positivo (prevê alto quando é baixo) e falso negativo (prevê baixo quando é alto) nas matrizes de confusão.\")\n",
    "else:\n",
    "    print(\"Arquivo não encontrado.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
